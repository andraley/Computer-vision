{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install scikit-video==1.1.11","metadata":{"id":"gv9PIZPI7hq-","outputId":"2d2845cd-a61d-4404-a4b7-09972a045357","execution":{"iopub.status.busy":"2022-08-22T06:39:07.638435Z","iopub.execute_input":"2022-08-22T06:39:07.639663Z","iopub.status.idle":"2022-08-22T06:39:19.181314Z","shell.execute_reply.started":"2022-08-22T06:39:07.639592Z","shell.execute_reply":"2022-08-22T06:39:19.179857Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Задание 7\n\nОбучить нейронную сеть для распознавания действий человека по видео на датасете KTH\nБиблиотеки: [Python, Tensorflow]\n\n","metadata":{"id":"mYjvMhEn7jPt"}},{"cell_type":"code","source":"import os\nimport glob\nimport random\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport skvideo.io\nimport tensorflow as tf","metadata":{"id":"SE2byI0P_zFj","execution":{"iopub.status.busy":"2022-08-22T06:39:19.183797Z","iopub.execute_input":"2022-08-22T06:39:19.184166Z","iopub.status.idle":"2022-08-22T06:39:24.402879Z","shell.execute_reply.started":"2022-08-22T06:39:19.184127Z","shell.execute_reply":"2022-08-22T06:39:24.401810Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"!wget http://www.csc.kth.se/cvap/actions/walking.zip\n!wget http://www.csc.kth.se/cvap/actions/jogging.zip\n!wget http://www.csc.kth.se/cvap/actions/running.zip\n!wget http://www.csc.kth.se/cvap/actions/boxing.zip\n!wget http://www.csc.kth.se/cvap/actions/handwaving.zip\n!wget http://www.csc.kth.se/cvap/actions/handclapping.zip","metadata":{"id":"6E31Aobg78WI","outputId":"6a967081-27a4-4992-ca94-87a20350ce19","execution":{"iopub.status.busy":"2022-08-22T06:39:24.404521Z","iopub.execute_input":"2022-08-22T06:39:24.405150Z","iopub.status.idle":"2022-08-22T07:01:52.030042Z","shell.execute_reply.started":"2022-08-22T06:39:24.405112Z","shell.execute_reply":"2022-08-22T07:01:52.028878Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"if 1:\n    !unzip walking.zip -d walking > /dev/null\n    !unzip jogging.zip -d jogging > /dev/null\n    !unzip running.zip -d running > /dev/null\n    !unzip boxing.zip -d boxing > /dev/null\n    !unzip handwaving.zip -d handwaving > /dev/null\n    !unzip handclapping.zip -d handclapping > /dev/null","metadata":{"id":"MDwJXwcF_IQZ","outputId":"dad5acb7-ff55-4789-ee02-28c80698a69f","execution":{"iopub.status.busy":"2022-08-22T07:01:52.033362Z","iopub.execute_input":"2022-08-22T07:01:52.033994Z","iopub.status.idle":"2022-08-22T07:02:07.748349Z","shell.execute_reply.started":"2022-08-22T07:01:52.033957Z","shell.execute_reply":"2022-08-22T07:02:07.747102Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"classes = [\n    'walking',\n    'jogging',\n    'running',\n    'boxing',\n    'handwaving',\n    'handclapping',\n]\n\ndataset = []\ndata_root = './'\nfor cls in classes:\n    print('Processing class: {}'.format(cls))\n    for fpath in glob.glob(os.path.join(data_root, cls, '*.avi')):\n        cls_idx = classes.index(cls)\n        dataset.append((fpath, cls_idx))","metadata":{"id":"olX68iPL--8n","outputId":"0a34a939-292f-465f-a33d-bb0b6c5a2a2f","execution":{"iopub.status.busy":"2022-08-22T07:02:07.750330Z","iopub.execute_input":"2022-08-22T07:02:07.750663Z","iopub.status.idle":"2022-08-22T07:02:07.765563Z","shell.execute_reply.started":"2022-08-22T07:02:07.750623Z","shell.execute_reply":"2022-08-22T07:02:07.764083Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"len(dataset)","metadata":{"id":"qyYvE-GXMrUE","outputId":"1ccf3908-0629-4a0c-b0c7-53c6d83375b5","execution":{"iopub.status.busy":"2022-08-22T07:02:07.766792Z","iopub.execute_input":"2022-08-22T07:02:07.767095Z","iopub.status.idle":"2022-08-22T07:02:07.776071Z","shell.execute_reply.started":"2022-08-22T07:02:07.767070Z","shell.execute_reply":"2022-08-22T07:02:07.774924Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"SUBSET_LEN = 100\nTEST_LEN = 10\n\nrandom.shuffle(dataset)\ntrain_dataset = dataset[:SUBSET_LEN]\ntest_dataset = dataset[SUBSET_LEN:SUBSET_LEN+TEST_LEN]","metadata":{"id":"Nppx5jblACpg","execution":{"iopub.status.busy":"2022-08-22T07:02:07.777597Z","iopub.execute_input":"2022-08-22T07:02:07.778035Z","iopub.status.idle":"2022-08-22T07:02:07.785259Z","shell.execute_reply.started":"2022-08-22T07:02:07.778002Z","shell.execute_reply":"2022-08-22T07:02:07.784157Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"videodata = skvideo.io.vread(train_dataset[0][0])\nvideodata = videodata.astype(np.float32) / 255.\nprint('videodata shape:', videodata.shape)\nplt.imshow(videodata[50, ...])","metadata":{"id":"i2Wu-Hj_Jb-M","outputId":"95a16132-f3dd-4edf-a4b8-1c5519e13467","execution":{"iopub.status.busy":"2022-08-22T07:02:07.788143Z","iopub.execute_input":"2022-08-22T07:02:07.789298Z","iopub.status.idle":"2022-08-22T07:02:08.361719Z","shell.execute_reply.started":"2022-08-22T07:02:07.789265Z","shell.execute_reply":"2022-08-22T07:02:08.360559Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"motion = np.mean(videodata[1:, ...] - videodata[:-1, ...], axis=3, keepdims=True)\nprint('motion shape:', motion.shape)\nplt.imshow(motion[50, ..., 0])","metadata":{"id":"5wjJA8C6K8Ic","outputId":"bf276c32-b54f-4775-bdbc-e72b64930c25","execution":{"iopub.status.busy":"2022-08-22T07:02:08.363659Z","iopub.execute_input":"2022-08-22T07:02:08.364020Z","iopub.status.idle":"2022-08-22T07:02:08.807043Z","shell.execute_reply.started":"2022-08-22T07:02:08.363984Z","shell.execute_reply":"2022-08-22T07:02:08.801730Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"model = tf.keras.Sequential([\n    tf.keras.layers.Conv3D(32, (5, 5, 5), (1, 2, 2), padding='same', activation='relu'),\n    tf.keras.layers.MaxPool3D((1, 2, 2), padding='same'),\n    tf.keras.layers.Conv3D(64, (5, 5, 5), (1, 2, 2), padding='same', activation='relu'),\n    tf.keras.layers.MaxPool3D((1, 2, 2), padding='same'),\n    tf.keras.layers.Conv3D(64, (3, 3, 3), (1, 2, 2), padding='same', activation='relu'),\n    tf.keras.layers.MaxPool3D((1, 2, 2), padding='same'),\n    tf.keras.layers.Conv3D(64, (3, 3, 3), (1, 1, 1), padding='same', activation=None),\n    tf.keras.layers.GlobalAveragePooling3D(),\n    tf.keras.layers.Dense(64, activation='relu'),\n    tf.keras.layers.Dense(6, activation=None),\n])","metadata":{"id":"X8qdOSjlKvGg","execution":{"iopub.status.busy":"2022-08-22T07:02:08.814326Z","iopub.execute_input":"2022-08-22T07:02:08.815422Z","iopub.status.idle":"2022-08-22T07:02:12.970646Z","shell.execute_reply.started":"2022-08-22T07:02:08.815377Z","shell.execute_reply":"2022-08-22T07:02:12.969689Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"inp = motion[None, ...]\nout = model(inp)\n\nprint('Input shape:', inp.shape)\nprint('Output shape:', out.shape)","metadata":{"id":"tOuwsKdDKvOr","outputId":"778f2704-603c-4f25-f5d0-f3975281b5ab","execution":{"iopub.status.busy":"2022-08-22T07:02:12.972156Z","iopub.execute_input":"2022-08-22T07:02:12.972537Z","iopub.status.idle":"2022-08-22T07:02:19.720382Z","shell.execute_reply.started":"2022-08-22T07:02:12.972502Z","shell.execute_reply":"2022-08-22T07:02:19.719325Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"NUM_EPOCHS = 10\nLEARNING_RATE = 0.001\n\nmodel.compile(\n    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n    optimizer=tf.keras.optimizers.Adam(LEARNING_RATE))\n\nwriter = tf.summary.create_file_writer('logs/exp1')","metadata":{"id":"R4z01SOALMAG","execution":{"iopub.status.busy":"2022-08-22T07:02:19.722127Z","iopub.execute_input":"2022-08-22T07:02:19.722846Z","iopub.status.idle":"2022-08-22T07:02:19.743234Z","shell.execute_reply.started":"2022-08-22T07:02:19.722801Z","shell.execute_reply":"2022-08-22T07:02:19.742386Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"global_step = 0\nfor ep in range(NUM_EPOCHS):\n    for iter, (fpath, label) in enumerate(dataset):\n        videodata = skvideo.io.vread(fpath)\n        videodata = videodata.astype(np.float32) / 255.\n        motion = np.mean(videodata[1:, ...] - videodata[:-1, ...], axis=3, keepdims=True)\n        x = motion[None, ...]\n        y = np.array(label)[None, ...]\n\n        loss_value = model.train_on_batch(x, y)\n\n        if iter % 10 == 0:\n            print(f'[{ep}/{NUM_EPOCHS}][{iter}/{len(dataset)}] Loss = {loss_value}')\n\n            with writer.as_default():\n                tf.summary.scalar('loss', loss_value, global_step)\n\n        global_step += 1","metadata":{"id":"VYFbxVMlLPCV","outputId":"79242a4b-3e1d-43cb-ebe0-eae6f52841cd","execution":{"iopub.status.busy":"2022-08-22T07:02:19.744344Z","iopub.execute_input":"2022-08-22T07:02:19.744601Z","iopub.status.idle":"2022-08-22T08:29:03.086060Z","shell.execute_reply.started":"2022-08-22T07:02:19.744578Z","shell.execute_reply":"2022-08-22T08:29:03.084746Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"%load_ext tensorboard\n%tensorboard --logdir logs","metadata":{"id":"1fqof9u5Ns2c","execution":{"iopub.status.busy":"2022-08-22T08:29:03.088033Z","iopub.execute_input":"2022-08-22T08:29:03.088437Z","iopub.status.idle":"2022-08-22T08:29:07.176015Z","shell.execute_reply.started":"2022-08-22T08:29:03.088397Z","shell.execute_reply":"2022-08-22T08:29:07.174879Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"Тестирование","metadata":{"id":"IpjwX7UDN63w"}},{"cell_type":"code","source":"fpath, cls_true = random.choice(test_dataset)\n\nvideodata = skvideo.io.vread(fpath)\nvideodata = videodata.astype(np.float32) / 255.\nplt.imshow(videodata[30, ...])\n\nmotion = np.mean(videodata[1:, ...] - videodata[:-1, ...], axis=3, keepdims=True)\n\nout = model(motion[None, ...])[0]\ncls_pred = np.argmax(out.numpy())\n\nprint('True class:', classes[cls_true])\nprint('Predicted class:', classes[cls_pred])","metadata":{"id":"ziD8il0BN1QO","execution":{"iopub.status.busy":"2022-08-22T08:29:07.178377Z","iopub.execute_input":"2022-08-22T08:29:07.179064Z","iopub.status.idle":"2022-08-22T08:29:08.162695Z","shell.execute_reply.started":"2022-08-22T08:29:07.179027Z","shell.execute_reply":"2022-08-22T08:29:08.161507Z"},"trusted":true},"execution_count":17,"outputs":[]}]}